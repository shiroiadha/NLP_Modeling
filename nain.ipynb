{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: instaloader in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (4.14)\n",
      "Requirement already satisfied: pandas in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: spacy in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: transformers in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from instaloader) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (8.3.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from requests>=2.25->instaloader) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from requests>=2.25->instaloader) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from requests>=2.25->instaloader) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from requests>=2.25->instaloader) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.2.0,>=1.1.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adhar\\.conda\\envs\\testing\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install instaloader pandas spacy transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instaloader\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Instaloader\n",
    "L = instaloader.Instaloader()\n",
    "\n",
    "# Optionally, login to your Instagram account\n",
    "# L.login('your_username', 'your_password')\n",
    "\n",
    "# Function to scrape posts from a profile\n",
    "def scrape_instagram_profile(username):\n",
    "    posts = []\n",
    "    profile = instaloader.Profile.from_username(L.context, username)\n",
    "\n",
    "    # Loop through the posts in the profile\n",
    "    for post in profile.get_posts():\n",
    "        posts.append(post.caption)  # Captions are where the text content is\n",
    "\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load pre-trained spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Process with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Remove stop words and punctuation\n",
    "    tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenoglossophilia_keywords = [\n",
    "    \"speak many languages\", \"fluent in\", \"i speak\", \"language polyglot\", \"i can speak\", \"speak without learning\"\n",
    "]\n",
    "\n",
    "def detect_xenoglossophilia(post_text):\n",
    "    for keyword in xenoglossophilia_keywords:\n",
    "        if keyword in post_text:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m posts \u001b[38;5;241m=\u001b[39m scrape_instagram_profile(username)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m posts:\n\u001b[1;32m---> 10\u001b[0m     processed_post \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detect_xenoglossophilia(processed_post):\n\u001b[0;32m     12\u001b[0m         users_with_xenoglossophilia\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m: instaloader\u001b[38;5;241m.\u001b[39mProfile\u001b[38;5;241m.\u001b[39mfrom_username(L\u001b[38;5;241m.\u001b[39mcontext, username)\u001b[38;5;241m.\u001b[39muserid,\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m: username\n\u001b[0;32m     15\u001b[0m         })\n",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_text\u001b[39m(text):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Convert to lowercase\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Process with spaCy\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(text)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# List to store user data\n",
    "users_with_xenoglossophilia = []\n",
    "\n",
    "# List of Instagram profiles to check\n",
    "profiles_to_check = ['adharasyid30', 'karenmizuki24', 'shiroiayaka78']\n",
    "\n",
    "for username in profiles_to_check:\n",
    "    posts = scrape_instagram_profile(username)\n",
    "    for post in posts:\n",
    "        processed_post = preprocess_text(post)\n",
    "        if detect_xenoglossophilia(processed_post):\n",
    "            users_with_xenoglossophilia.append({\n",
    "                'user_id': instaloader.Profile.from_username(L.context, username).userid,\n",
    "                'username': username\n",
    "            })\n",
    "\n",
    "# Store the results in a Pandas DataFrame\n",
    "df = pd.DataFrame(users_with_xenoglossophilia)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded session from C:\\Users\\adhar\\AppData\\Local\\Instaloader\\session-shiroiayaka78.\n",
      "Loaded session successfully.\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import instaloader\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize Instaloader\n",
    "L = instaloader.Instaloader()\n",
    "\n",
    "# Login to Instagram using your credentials and session file\n",
    "username = 'shiroiayaka78'  # Replace with your Instagram username\n",
    "password = 'Ayakasan1202'  # Replace with your Instagram password\n",
    "session_file = 'session.json'  # The file where the session will be saved\n",
    "\n",
    "# Try to load the session if it exists\n",
    "try:\n",
    "    L.load_session_from_file(username)  # Try to load session from file\n",
    "    print(\"Loaded session successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Session file not found. Logging in...\")\n",
    "    L.login(username, password)  # Log in if the session is not found\n",
    "    L.save_session_to_file()  # Save the session to file for future use\n",
    "\n",
    "# Function to scrape posts from a profile (limit to 100 posts)\n",
    "def scrape_instagram_profile(username, max_posts=100):\n",
    "    posts = []\n",
    "    try:\n",
    "        profile = instaloader.Profile.from_username(L.context, username)\n",
    "        count = 0\n",
    "        # Loop through the posts in the profile\n",
    "        for post in profile.get_posts():\n",
    "            if count >= max_posts:\n",
    "                break\n",
    "            posts.append(post.caption)  # Captions are where the text content is\n",
    "            count += 1\n",
    "    except instaloader.exceptions.ProfileNotExistsException:\n",
    "        return None  # If the profile doesn't exist, return None\n",
    "\n",
    "    return posts\n",
    "\n",
    "# Function to preprocess the text using spaCy\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    doc = nlp(text)  # Process the text with spaCy\n",
    "\n",
    "    # Remove stopwords and punctuation\n",
    "    tokens = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Function to detect xenoglossophilia based on keyword matching\n",
    "xenoglossophilia_keywords = [\n",
    "    \"speak many languages\", \"fluent in\", \"i speak\", \"language polyglot\", \"i can speak\", \"speak without learning\"\n",
    "]\n",
    "\n",
    "def detect_xenoglossophilia(post_text):\n",
    "    for keyword in xenoglossophilia_keywords:\n",
    "        if keyword in post_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# List of profiles (channels) to check\n",
    "profiles_to_check = [  # Add Instagram usernames here\n",
    "]\n",
    "\n",
    "# Collect user data (limit to 100 data points)\n",
    "users_with_xenoglossophilia = []\n",
    "\n",
    "# Scrape profiles and check posts for xenoglossophilia\n",
    "for username in profiles_to_check:\n",
    "    posts = scrape_instagram_profile(username)\n",
    "    if posts is not None:\n",
    "        for post in posts:\n",
    "            processed_post = preprocess_text(post)\n",
    "            if detect_xenoglossophilia(processed_post):\n",
    "                users_with_xenoglossophilia.append({\n",
    "                    'user_id': instaloader.Profile.from_username(L.context, username).userid,\n",
    "                    'username': username\n",
    "                })\n",
    "\n",
    "# Store the results in a Pandas DataFrame\n",
    "df = pd.DataFrame(users_with_xenoglossophilia)\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file (optional)\n",
    "df.to_csv('xenoglossophilia_users.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
